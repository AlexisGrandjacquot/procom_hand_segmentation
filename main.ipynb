{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I/ Loading CT scan  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "#Function to load the image\n",
    "def get_image_label(img_number):\n",
    "    load_image = nib.load(f\"train-images/CT_{img_number}.nii.gz\").get_fdata()\n",
    "    load_label = nib.load(f\"train-images/labels/final/CT_{img_number}.nii.gz\").get_fdata()\n",
    "    return load_image, load_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the image\n",
    "img_number=2\n",
    "load_image, load_label=get_image_label(img_number)\n",
    "load_image=load_image.swapaxes(1,2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II/ Data visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VFunction to visualise a frame of the CT scan\n",
    "def visualise_img(img,tranche):\n",
    "    fig, ax = plt.subplots()\n",
    "    img_tranche=img[:,:,tranche]\n",
    "           \n",
    "    ax.imshow(img_tranche, cmap='gray')  \n",
    "    plt.show()\n",
    "\n",
    "tranche_number=load_image.swapaxes(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interface\n",
    "from ipywidgets import widgets, interact,fixed\n",
    "\n",
    "tranche_number=load_image.shape[2]\n",
    "interact(visualise_img, img=fixed(load_image), tranche=(1,tranche_number,1),threshold=(100,1000,1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III/ Bone segmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import convolve2d\n",
    "import cv2 as cv2\n",
    "import skimage\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##Function to denoise the CT_SCAN using fastNlMeansDenoisingMulti from cv2###\n",
    "## Return the CT scan denoised with a normalised intensity    \n",
    "def denoise_NL(load_image,threshold,h):\n",
    "    denoise_matrix=np.zeros(load_image.shape)\n",
    "\n",
    "    for k in range(load_image.shape[2]-10):\n",
    "        factor=250/np.max(load_image[:,:,k:(k+10)])\n",
    "\n",
    "        #We use frame from k, k+10 to denoise the frame k+1##\n",
    "        imgs_to_denoise=np.where(load_image[:,:,k:(k+10)]>threshold,load_image[:,:,k:(k+10)],0)\n",
    "        imgs_to_denoise=imgs_to_denoise*factor\n",
    "        imgs_to_denoise=imgs_to_denoise.astype(np.uint8).T\n",
    "\n",
    "        img=cv2.fastNlMeansDenoisingMulti(imgs_to_denoise,h=h,imgToDenoiseIndex=1,temporalWindowSize=3)\n",
    "        img=img.astype(float)/factor\n",
    "        img=img/250\n",
    "        img=img.T\n",
    "\n",
    "        denoise_matrix[:,:,k+1]=img\n",
    "    return denoise_matrix\n",
    "\n",
    "#Function to denoise a single frame of the CT_scan##\n",
    "def denoise_NL_single_frame(load_image,frame,threshold,h):\n",
    "    factor=250/np.max(load_image[:,:,frame:(frame+10)])\n",
    "\n",
    "        #We use frame from k, k+10 to denoise the frame k+1##\n",
    "    imgs_to_denoise=np.where(load_image[:,:,frame:(frame+10)]>threshold,load_image[:,:,frame:(frame+10)],0)\n",
    "    imgs_to_denoise=imgs_to_denoise*factor\n",
    "    imgs_to_denoise=imgs_to_denoise.astype(np.uint8).T\n",
    "\n",
    "    img=cv2.fastNlMeansDenoisingMulti(imgs_to_denoise,h=h,imgToDenoiseIndex=1,temporalWindowSize=3)\n",
    "    img=img.astype(float)/factor\n",
    "    img=img/250\n",
    "    img=img.T\n",
    "\n",
    "    return img\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##Get the center coordonates of a certain label##\n",
    "def get_center_label(contour_image,label):\n",
    "    coordonates=np.where(contour_image==label)\n",
    "    return np.mean(coordonates, axis=1)\n",
    "\n",
    "#Get the contour of each bones from the CT_scan at a certain frame\n",
    "#return the contour imaged. All contours are filled\n",
    "def get_segmentation_frame(img_after_thresh,frame,volume_min_pixel):\n",
    "    if frame==None:\n",
    "        cv_image=250*img_after_thresh.astype(np.uint8)\n",
    "    else:\n",
    "        cv_image=250*img_after_thresh[:,:,frame].astype(np.uint8)\n",
    "    ##apply filter \n",
    "    result = cv_image\n",
    "    ##Get contour from the image\n",
    "    contours, _ = cv2.findContours(result.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    contour_image = np.zeros_like(cv_image,dtype=np.uint8)\n",
    "    contour_image = cv2.UMat(contour_image)\n",
    "    # Draw contours on the black image\n",
    "    for i in range(len(contours)):\n",
    "        \n",
    "        cv2.drawContours(contour_image, [contours[i]], -1, (1+i, 1+i, 1+i),thickness=cv2.FILLED)\n",
    "\n",
    "    contour_image = contour_image.get()\n",
    "    ##\n",
    "    for contour_label in range(1,len(contours)+1):\n",
    "        if(np.count_nonzero(contour_image==contour_label) < volume_min_pixel):\n",
    "            contour_image=np.where(contour_image==contour_label,0,contour_image)\n",
    "    return contour_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "##Function visualise the segmentation given \n",
    "def choose_tresh_h(threshold,frame,load_image,h):\n",
    "    \n",
    "    img_denoised=denoise_NL_single_frame(load_image=load_image,frame=frame,threshold=threshold,h=h)\n",
    "\n",
    "    mask=get_segmentation_frame(img_denoised,frame=None,volume_min_pixel=50)\n",
    "    fig, ax = plt.subplots()\n",
    "    yellow_cmap = LinearSegmentedColormap.from_list(\"yellow_cmap\", [(1, 1, 0), (1, 1, 0)], N=2)\n",
    "    alpha_mask = np.where(mask != 0, 0.5, 0)\n",
    "    nb_labels=np.max(mask)\n",
    "    for i in range(1,int(nb_labels)+1):\n",
    "        ax.scatter(get_center_label(mask,i)[1],get_center_label(mask,i)[0])\n",
    "    \n",
    "\n",
    "    ax.imshow(load_image[:,:,frame],cmap='gray')\n",
    "    ax.imshow(mask,cmap=yellow_cmap,alpha=alpha_mask)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Don't choose more than 100 frames as this function can take a long time to be executed##\n",
    "interact(choose_tresh_h, load_image=fixed(load_image),frame=(0,100,1),threshold=(200,300,1),h=(5,20,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Put the value of h and threshold choosen think to the cell above\n",
    "threshold=275\n",
    "h=20\n",
    "##\n",
    "\n",
    "###Denoising of the CT scan, this can take between 5 and 10 mins\n",
    "masks_image=np.zeros(load_image.shape)\n",
    "masks_bones=np.zeros(load_image.shape)\n",
    "img_after_thresh=denoise_NL(load_image=load_image,threshold=threshold,h=20)#threshold_on_image(load_image,threshold=threshold)\n",
    "\n",
    "print(\"Just finish denoising\")\n",
    "\n",
    "\n",
    "\n",
    "for k in range(0,load_image.shape[2]):\n",
    "    #masks_bones[:,:,k]= get_segmentation_all_bones(img_after_thresh,k,100,sigma_x=sigma_x,sigma_y=sigma_y,threshold=threshold_all_bones)\n",
    "    masks_image[:,:,k]=get_segmentation_frame(img_after_thresh,k,50)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "#Function to visualise to segmentation on all the Ct_scan\n",
    "def visu_frame_mask(load_image,mask,frame):\n",
    "    fig, ax = plt.subplots()\n",
    "    yellow_cmap = LinearSegmentedColormap.from_list(\"yellow_cmap\", [(1, 1, 0), (1, 1, 0)], N=2)\n",
    "    alpha_mask = np.where(mask[:, :, frame] != 0, 0.5, 0)\n",
    "\n",
    "    nb_labels=np.max(mask[:, :, frame])\n",
    "    for i in range(1,int(nb_labels)+1):\n",
    "        ax.scatter(get_center_label(mask[:, :, frame],i)[1],get_center_label(mask[:, :, frame],i)[0])\n",
    "\n",
    "    ax.imshow(load_image[:,:,frame],cmap='gray')\n",
    "    ax.imshow(mask[:,:,frame],cmap=yellow_cmap,alpha=alpha_mask)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualisation of the segmentation of the segmentation on the CT_scan\n",
    "interact(visu_frame_mask, load_image=fixed(load_image),mask=fixed(masks_image) ,frame=(1,tranche_number,1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV/ Tracking \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creation of function that will be used\n",
    "from skimage.segmentation import active_contour\n",
    "from skimage import io, color, draw \n",
    "def get_snake_contours(previous_clusters,masks_previous_frame,load_image_current_frame):\n",
    "        masks_current_frame=np.zeros(masks_previous_frame.shape).astype(np.uint8)\n",
    "        print()\n",
    "        label_assignement={}\n",
    "\n",
    "        for previous_cluster in previous_clusters:\n",
    "                label,_,_=previous_cluster\n",
    "                binary_imged=np.where(masks_previous_frame==label,250,0).astype(np.uint8)\n",
    "                contours, _ = cv2.findContours(binary_imged.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                contour=contours[0]\n",
    "                snake = active_contour(load_image_current_frame,contour.squeeze().reshape(-1, 2), alpha=0.002, beta=0.1, gamma=1)\n",
    "                print(snake.shape)\n",
    "\n",
    "                rr, cc = draw.polygon(snake[:, 1], snake[:, 0], masks_current_frame.shape)\n",
    "                masks_current_frame[rr,cc]=label\n",
    "\n",
    "                \n",
    "                #cv2.drawContours(masks_current_frame, contour, -1, (int(label), int(label), int(label)),thickness=cv2.FILLED)\n",
    "                \n",
    "                label_assignement[label]=label\n",
    "                \n",
    "        return masks_current_frame,label_assignement\n",
    "\n",
    "\n",
    "def defusion(previous_clusters,masks_previous_frame,load_image_current_frame):\n",
    "        masks_current_frame=np.zeros(masks_previous_frame.shape).astype(np.uint8)\n",
    "        print()\n",
    "        label_assignement={}\n",
    "\n",
    "        for previous_cluster in previous_clusters:\n",
    "                label,_,_=previous_cluster\n",
    "                binary_imged=np.where(masks_previous_frame==label,250,0).astype(np.uint8)\n",
    "                contours, _ = cv2.findContours(binary_imged.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                contour=contours[0]\n",
    "                snake = active_contour(load_image_current_frame,contour.squeeze().reshape(-1, 2), alpha=0.002, beta=0.1, gamma=1)\n",
    "                print(snake.shape)\n",
    "\n",
    "                rr, cc = draw.polygon(snake[:, 1], snake[:, 0], masks_current_frame.shape)\n",
    "                masks_current_frame[rr,cc]=label\n",
    "\n",
    "                \n",
    "                #cv2.drawContours(masks_current_frame, contour, -1, (int(label), int(label), int(label)),thickness=cv2.FILLED)\n",
    "                \n",
    "                label_assignement[label]=label\n",
    "                \n",
    "        return masks_current_frame,label_assignement\n",
    "\n",
    "def get_volumes(masks,label,frame):\n",
    "        return np.sum(masks[:,:,frame]==label)\n",
    "\n",
    "def get_cluster_asignement(previous_clusters,current_clusters,masks_previous_frame,masks_current_frame,distance_max):\n",
    "        label_assignement={}\n",
    "        for cluster in current_clusters:\n",
    "                overlapping_max=0\n",
    "                number_of_over_lapping=0\n",
    "                label,x,y=cluster\n",
    "                \n",
    "                label_assignement[label]=None\n",
    "                for previous_cluster in previous_clusters:\n",
    "                      \n",
    "                      label_previous,x_previous,y_previous=previous_cluster\n",
    "                      distance=np.sqrt((x-x_previous)**2+(y-y_previous)**2)\n",
    "                \n",
    "                      if distance<distance_max:\n",
    "                                overlapping=np.sum( np.where(masks_previous_frame==label_previous,1,0)*np.where(masks_current_frame==label,1,0))/np.sum(np.where(masks_current_frame==label,1,0))\n",
    "                                \n",
    "                                if overlapping>0.2:\n",
    "                                       number_of_over_lapping+=1\n",
    "\n",
    "\n",
    "                                if overlapping_max<overlapping:\n",
    "                                       overlapping_max=overlapping\n",
    "                                       label_assignement[label]=label_previous\n",
    "\n",
    "                if number_of_over_lapping>1:\n",
    "                       print(\"detected one fusion\")\n",
    "        return label_assignement\n",
    "\n",
    "\n",
    "def get_cluster_asignement_no_fusion(previous_clusters,current_clusters,masks_previous_frame,masks_current_frame,load_image_previous_frame,load_image_current_frame,distance_max):\n",
    "        label_assignement={}\n",
    "        for cluster in current_clusters:\n",
    "                overlapping_max=0\n",
    "                number_of_over_lapping=0\n",
    "                label,x,y=cluster\n",
    "                \n",
    "                label_assignement[label]=None\n",
    "                for previous_cluster in previous_clusters:\n",
    "                      \n",
    "                      label_previous,x_previous,y_previous=previous_cluster\n",
    "                      distance=np.sqrt((x-x_previous)**2+(y-y_previous)**2)\n",
    "                \n",
    "                      if distance<distance_max:\n",
    "                                overlapping=np.sum( np.where(masks_previous_frame==label_previous,1,0)*np.where(masks_current_frame==label,1,0))/np.sum(np.where(masks_current_frame==label,1,0))\n",
    "                                \n",
    "                                if overlapping>0.2:\n",
    "                                       number_of_over_lapping+=1\n",
    "\n",
    "\n",
    "                                if overlapping_max<overlapping:\n",
    "                                       overlapping_max=overlapping\n",
    "                                       label_assignement[label]=label_previous\n",
    "\n",
    "                if number_of_over_lapping>1:\n",
    "                       print(\"Using defusion\")\n",
    "                       masks_current_frame,label_assignement=defusion(previous_clusters,masks_previous_frame,load_image_current_frame)\n",
    "                       break\n",
    "        return label_assignement, masks_current_frame\n",
    "\n",
    "                                       \n",
    "\n",
    "              \n",
    "\n",
    "#get_snake_contours(previous_clusters,masks_previous_frame,load_image_current_frame)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracking using naif association\n",
    "def tracking(masks):\n",
    "    masks_tracking=np.zeros(masks.shape)\n",
    "    masks_tracking[:,:,1]=masks[:,:,1]\n",
    "    previous_clusters=[]#[(label,volume,x,y)] with x,y the center of the label\n",
    "    labels=np.unique(masks[:,:,1][masks[:,:,1]!=0])\n",
    "    #print(labels)\n",
    "    max_label=np.max(labels)+1\n",
    "\n",
    "    for label in labels:\n",
    "        #volume=get_volumes(masks=masks,label=label,frame=0)\n",
    "        x,y=get_center_label(masks[:,:,1],label)\n",
    "        previous_clusters.append((label,x,y))\n",
    "\n",
    "    for frame in range(2,masks.shape[2]):\n",
    "        print(f\"Iteration {frame} on {masks.shape[2]}\")\n",
    "        current_clusters=[]\n",
    "        labels=np.unique(masks[:,:,frame][masks[:,:,frame]!=0])\n",
    "        #print(labels)\n",
    "        previous_clusters=[]\n",
    "        labels_previous=np.unique(masks_tracking[:,:,frame-1][masks_tracking[:,:,frame-1]!=0])\n",
    "        for label in labels_previous:\n",
    "        #volume=get_volumes(masks=masks,label=label,frame=0)\n",
    "            x,y=get_center_label(masks_tracking[:,:,frame-1],label)\n",
    "            previous_clusters.append((label,x,y))\n",
    "\n",
    "        for label in labels:\n",
    "            \n",
    "            x,y=get_center_label(masks[:,:,frame],label)\n",
    "            current_clusters.append((label,x,y))\n",
    "\n",
    "        label_assignement=get_cluster_asignement(previous_clusters,current_clusters,masks_tracking[:,:,frame-1],masks[:,:,frame],distance_max=300)\n",
    "        \n",
    "\n",
    "        #previous_clusters=current_clusters\n",
    "         \n",
    "        for current_label in label_assignement.keys():\n",
    "            if label_assignement[current_label]!=None:\n",
    "                indexs_current_label=np.where(masks[:,:,frame]==current_label)\n",
    "                masks_tracking[:,:,frame][indexs_current_label]=label_assignement[current_label]\n",
    "            else:\n",
    "                max_label+=1\n",
    "                indexs_current_label=np.where(masks[:,:,frame]==current_label)\n",
    "                masks_tracking[:,:,frame][indexs_current_label]=max_label\n",
    "    return masks_tracking\n",
    "\n",
    "\n",
    "#Try to correct error from the naif tracking algo\n",
    "\n",
    "#Using the snake algo to detect contours when an error has benn detected\n",
    "def tracking_no_fusion(masks,load_image_denoised):\n",
    "    masks_tracking=np.zeros(masks.shape)\n",
    "    masks_tracking[:,:,1]=masks[:,:,1]\n",
    "    previous_clusters=[]#[(label,volume,x,y)] with x,y the center of the label\n",
    "    labels=np.unique(masks[:,:,1][masks[:,:,1]!=0])\n",
    "    print(labels)\n",
    "    if len(labels)>=1:\n",
    "        max_label=np.max(labels)+1\n",
    "    else:\n",
    "        max_label=1\n",
    "\n",
    "    for label in labels:\n",
    "        #volume=get_volumes(masks=masks,label=label,frame=0)\n",
    "        x,y=get_center_label(masks[:,:,1],label)\n",
    "        previous_clusters.append((label,x,y))\n",
    "\n",
    "    for frame in range(2,masks.shape[2]):\n",
    "        print(f\"Iteration {frame} on {masks.shape[2]}\")\n",
    "        current_clusters=[]\n",
    "        labels=np.unique(masks[:,:,frame][masks[:,:,frame]!=0])\n",
    "        #print(labels)\n",
    "        previous_clusters=[]\n",
    "        labels_previous=np.unique(masks_tracking[:,:,frame-1][masks_tracking[:,:,frame-1]!=0])\n",
    "        for label in labels_previous:\n",
    "        #volume=get_volumes(masks=masks,label=label,frame=0)\n",
    "            x,y=get_center_label(masks_tracking[:,:,frame-1],label)\n",
    "            previous_clusters.append((label,x,y))\n",
    "\n",
    "        for label in labels:\n",
    "            \n",
    "            x,y=get_center_label(masks[:,:,frame],label)\n",
    "            current_clusters.append((label,x,y))\n",
    "\n",
    "        label_assignement,mask_current_frame=get_cluster_asignement_no_fusion(previous_clusters,current_clusters,masks_tracking[:,:,frame-1],masks[:,:,frame],load_image_denoised[:,:,frame-1],load_image_denoised[:,:,frame],distance_max=300)\n",
    "        \n",
    "\n",
    "        #previous_clusters=current_clusters\n",
    "         \n",
    "        for current_label in label_assignement.keys():\n",
    "            if label_assignement[current_label]!=None:\n",
    "                indexs_current_label=np.where(mask_current_frame==current_label)\n",
    "                masks_tracking[:,:,frame][indexs_current_label]=label_assignement[current_label]\n",
    "            else:\n",
    "                max_label+=1\n",
    "                indexs_current_label=np.where(mask_current_frame==current_label)\n",
    "                masks_tracking[:,:,frame][indexs_current_label]=max_label\n",
    "    return masks_tracking\n",
    "\n",
    "\n",
    "masks_tracking=tracking_no_fusion(masks=masks_image,load_image_denoised=img_after_thresh)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visu_tracking(load_image,mask,frame):\n",
    "        fig, ax = plt.subplots()\n",
    "       \n",
    "        num_labels = 6#len(np.unique(mask))\n",
    "        print(num_labels)\n",
    "        colors = plt.cm.tab20c(np.linspace(0, 1, num_labels))  # Generate colors from the 'tab10' colormap\n",
    "        custom_cmap = LinearSegmentedColormap.from_list(\"custom_cmap\", colors, N=num_labels)\n",
    "\n",
    "        alpha_mask = np.where(mask[:, :, frame] != 0, 0.5, 0)\n",
    "\n",
    "        nb_labels=np.max(mask[:, :, frame])\n",
    "        for i in range(1,int(nb_labels)+1):\n",
    "            ax.scatter(get_center_label(mask[:, :, frame],i)[1],get_center_label(mask[:, :, frame],i)[0])\n",
    "\n",
    "        ax.imshow(load_image[:,:,frame],cmap='gray')\n",
    "        ax.imshow(mask[:,:,frame],cmap=custom_cmap,alpha=alpha_mask)\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(visu_tracking, load_image=fixed(load_image),mask=fixed(masks_tracking) ,frame=(0,740,1));\n",
    "#interact(visu_frame_mask, load_image=fixed(load_image),mask=fixed(masks_tracking) ,frame=(1,tranche_number,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mask(mask,filename):\n",
    "    nifti_img = nib.Nifti1Image(mask, np.eye(4))\n",
    "    nib.save(nifti_img, filename)\n",
    "masks_tracking=masks_tracking.swapaxes(1,2)\n",
    "save_mask(masks_tracking,'./masks_from_python/hand_2_bis_new.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mask_header(original_file,to_convert_file):\n",
    "    header=nib.load(f\"train-images/CT_{original_file}.nii.gz\").header\n",
    "    created_mask = nib.load(to_convert_file).get_fdata()\n",
    "    nifti_img = nib.Nifti1Image(created_mask, np.eye(4),header=header)\n",
    "    nib.save(nifti_img, \"./masks_from_python/hand_2_bis_hey.nii.gz\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "convert_mask_header(2,'./masks_from_python/hand_2_bis.nii.gz')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "procomenv",
   "language": "python",
   "name": "procomenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
